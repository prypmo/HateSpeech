{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb73896f",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a7187",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ffc1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab32420",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install clean-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec64211",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b10cecee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Priscila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import unidecode \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from cleantext import clean\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords') \n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b44e201",
   "metadata": {},
   "source": [
    "### Reading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7021508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = pd.read_excel(\"Data/Tweet_Processed_DataCleaning_Test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c1f5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file.to_csv (\"Data/Tweet_Processed_DataCleaning_Test.csv\", index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ae52a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date_</th>\n",
       "      <th>Time_</th>\n",
       "      <th>User</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>22:49:14</td>\n",
       "      <td>NonDucorDuco11</td>\n",
       "      <td>@EuEdsonDuarte @LiloVLOG @jairbolsonaro Exatam...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>17:48:18</td>\n",
       "      <td>Circuito_D</td>\n",
       "      <td>A China fecha o primeiro laboratório do mundo ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>20:42:25</td>\n",
       "      <td>rafaelbboa</td>\n",
       "      <td>Janeiro: China mente sobre a % de mortos nos c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>15:18:53</td>\n",
       "      <td>DiabinhaBem</td>\n",
       "      <td>Nível de poluição na China cai drasticamente a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>19:20:35</td>\n",
       "      <td>therezafontoura</td>\n",
       "      <td>@eikebatista Os 19 que cruzam os oceanos traze...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                Date_     Time_             User  \\\n",
       "0         0.0  2020-01-03 00:00:00  22:49:14   NonDucorDuco11   \n",
       "1         1.0  2020-01-03 00:00:00  17:48:18       Circuito_D   \n",
       "2         2.0  2020-01-03 00:00:00  20:42:25       rafaelbboa   \n",
       "3         3.0  2020-01-03 00:00:00  15:18:53      DiabinhaBem   \n",
       "4         4.0  2020-01-03 00:00:00  19:20:35  therezafontoura   \n",
       "\n",
       "                                               Tweet  Unnamed: 5 Unnamed: 6  \n",
       "0  @EuEdsonDuarte @LiloVLOG @jairbolsonaro Exatam...         0.0        NaN  \n",
       "1  A China fecha o primeiro laboratório do mundo ...         0.0        NaN  \n",
       "2  Janeiro: China mente sobre a % de mortos nos c...         0.0        NaN  \n",
       "3  Nível de poluição na China cai drasticamente a...         0.0        NaN  \n",
       "4  @eikebatista Os 19 que cruzam os oceanos traze...         0.0        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_data = pd.read_csv('Data/Tweet_Processed_DataCleaning_Test.csv')\n",
    "cleaning_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50da66a",
   "metadata": {},
   "source": [
    "### Fixing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9e3146",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_data[\"Label\"] = cleaning_data[\"Unnamed: 5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee53c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EuEdsonDuarte @LiloVLOG @jairbolsonaro Exatam...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A China fecha o primeiro laboratório do mundo ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janeiro: China mente sobre a % de mortos nos c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nível de poluição na China cai drasticamente a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@eikebatista Os 19 que cruzam os oceanos traze...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Label\n",
       "0  @EuEdsonDuarte @LiloVLOG @jairbolsonaro Exatam...    0.0\n",
       "1  A China fecha o primeiro laboratório do mundo ...    0.0\n",
       "2  Janeiro: China mente sobre a % de mortos nos c...    0.0\n",
       "3  Nível de poluição na China cai drasticamente a...    0.0\n",
       "4  @eikebatista Os 19 que cruzam os oceanos traze...    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaning_data = cleaning_data[['Tweet', 'Label']]\n",
    "cleaning_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "334c31f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24200 entries, 0 to 24199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Tweet   24200 non-null  object \n",
      " 1   Label   24200 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 378.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaning_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92a20d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_data = cleaning_data.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9704a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 24200 entries, 0 to 24199\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Tweet   24200 non-null  object \n",
      " 1   Label   24200 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 567.2+ KB\n"
     ]
    }
   ],
   "source": [
    "cleaning_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81daf9d0",
   "metadata": {},
   "source": [
    "### Regular Data Cleaning for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b830710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@EuEdsonDuarte @LiloVLOG @jairbolsonaro Exatam...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A China fecha o primeiro laboratório do mundo ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Janeiro: China mente sobre a % de mortos nos c...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nível de poluição na China cai drasticamente a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@eikebatista Os 19 que cruzam os oceanos traze...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Label\n",
       "0  @EuEdsonDuarte @LiloVLOG @jairbolsonaro Exatam...    0.0\n",
       "1  A China fecha o primeiro laboratório do mundo ...    0.0\n",
       "2  Janeiro: China mente sobre a % de mortos nos c...    0.0\n",
       "3  Nível de poluição na China cai drasticamente a...    0.0\n",
       "4  @eikebatista Os 19 que cruzam os oceanos traze...    0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_nlp_cleaning = cleaning_data.copy()\n",
    "data_nlp_cleaning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6baf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    \"\"\"\n",
    "    This method will remove all ocurrences of urls in the tweets\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" after removal of all ocurrences of urls.        \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    remove_url = re.sub(r'http\\S+', '', text)\n",
    "    remove_com = re.sub(r\"\\ [A-Za-z]*\\.com\", \" \", remove_url)\n",
    "    return remove_com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f408e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_characters(text):\n",
    "    \"\"\"\n",
    "    This method will remove all accented from the character in the tweets\n",
    "    \n",
    "    arguments:\n",
    "        input_text: \"text\" of type \"String\". \n",
    "                    \n",
    "    return:\n",
    "        value: \"text\" with removed accented characters.        \n",
    "        \n",
    "    \"\"\"\n",
    "    text = unidecode.unidecode(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88ba68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case_text(text):\n",
    "    \n",
    "    \"\"\"\n",
    "    The method will convert the tweet in lower case.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "         value: text in lowercase\n",
    "    \n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afd59306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \"\"\"\n",
    "    This method will remove specail characters from the tweets.   \n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text with removed special characters that don't require.\n",
    "    \n",
    "   \"\"\"\n",
    "    text_formatted = re.sub(r\"[^a-zA-Z-,.?!]+\", ' ', text) \n",
    "    return text_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a3d819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mention(text):\n",
    "    \"\"\"\n",
    "    This method will remove mention from the tweet.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text after remove all mentions.\n",
    "    \n",
    "   \"\"\"\n",
    "    no_mention = re.sub(\"@[A-Za-z0-9_]+\",\"\", text)  \n",
    "    return no_mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac86803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    \"\"\"\n",
    "    This method will remove emojis from the tweet.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text after remove all emojis.\n",
    "    \n",
    "   \"\"\"\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1608fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = stopwords.words('portuguese') \n",
    "stoplist = set(stoplist)\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    This method will remove stopwords from the tweet.\n",
    "    \n",
    "    arguments:\n",
    "         input_text: \"text\" of type \"String\".\n",
    "         \n",
    "    return:\n",
    "        value: Text after omitted all stopwords.\n",
    "    \n",
    "   \"\"\"\n",
    "    text = repr(text)\n",
    "    No_StopWords = [word for word in word_tokenize(text) if word.lower() not in stoplist ]\n",
    "    words_string = ' '.join(No_StopWords)    \n",
    "    return words_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43333ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Priscila\\AppData\\Local\\Temp/ipykernel_15920/2105613259.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_nlp_cleaning['Tweet'][i] = temp\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>euedsonduarte lilovlog jairbolsonaro exatamen...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a china fecha o primeiro laboratorio do mundo ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>janeiro china mente sobre a de mortos nos caso...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nivel de poluicao na china cai drasticamente a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eikebatista os que cruzam os oceanos trazem u...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  Label\n",
       "0   euedsonduarte lilovlog jairbolsonaro exatamen...    0.0\n",
       "1  a china fecha o primeiro laboratorio do mundo ...    0.0\n",
       "2  janeiro china mente sobre a de mortos nos caso...    0.0\n",
       "3  nivel de poluicao na china cai drasticamente a...    0.0\n",
       "4   eikebatista os que cruzam os oceanos trazem u...    0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(data_nlp_cleaning['Tweet'])):\n",
    "    temp = data_nlp_cleaning.iloc[i, 0]\n",
    "    #removing url\n",
    "    temp = remove_url(temp)\n",
    "    temp = remove_accented_characters(temp)\n",
    "    temp = lower_case_text(temp)\n",
    "    temp = remove_special_characters(temp)\n",
    "    temp = remove_mention(temp)\n",
    "    temp = remove_emoji(temp)\n",
    "    data_nlp_cleaning['Tweet'][i] = temp\n",
    "    #data_nlp_cleaning.loc[i, 0] = temp\n",
    "    \n",
    "data_nlp_cleaning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "388ad43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nlp_cleaning.to_csv (\"Data/Tweet_Processed_DataCleaning_Done.csv\", index = None, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
